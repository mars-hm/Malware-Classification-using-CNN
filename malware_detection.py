import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import matplotlib.pyplot as plt
import pathlib

print("---- IMAGE PREPROCESSING STARTS ----")
train_dir = pathlib.Path('D:\\M.Sc CS\\AI\\Malware Classification using CNN\\malware\\train')
test_dir = pathlib.Path('D:\\M.Sc CS\\AI\\Malware Classification using CNN\\malware\\test')
batch_size = 64
img_height = 180
img_width = 180
AUTOTUNE = tf.data.AUTOTUNE

print("--------------------------------------\n")
print("Data Loading Process\n")

#image preprocessing - train dataset
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    validation_split=None, #validation/testing split
    image_size=(img_height, img_width),
    batch_size=batch_size)

#image preprocessing - test dataset
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  test_dir,
  validation_split=None,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
num_classes = len(class_names)
plt.bar(class_counts.keys(), class_counts.values())
plt.xlabel('Class')
plt.ylabel('Number of Images')
plt.title('Class Distribution in Training Data')
plt.show()

normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_dir.map(lambda x, y: (normalization_layer(x), y))
test_ds = test_dir.map(lambda x, y: (normalization_layer(x), y))


data_augmentation = tf.keras.Sequential(
    [
        tf.keras.layers.preprocessing.RandomFlip("horizontal", input_shape=(img_width, img_height, 3)),
    ]
)
train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))

model = tf.keras.Sequential([
  # data_augmentation, #Add if augmentation is needed.
  #cl1
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  #cl2
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  #cl3
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  #flattening
  tf.keras.layers.Flatten(),
  #fcl
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dense(num_classes),
])


print("--------------------------------------\n")
model.summary()
print("--------------------------------------\n")

model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])


print("--------------------------------------\n")
print("Training Started.\n")
history = model.fit(train_ds,validation_data=val_ds,epochs=10)
print("Training Finished.\n")
print("--------------------------------------\n")


# Plot and save accuracy
plt.plot(history.epoch,history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
#plt.savefig('C:\\Users\\HP\\Downloads\\Whole Dataset\\tumor_accuracy_plot.png')

# Clear the previous plot
plt.clf()

# Plot and save loss
plt.plot(history.epoch,history.history['loss'], label='loss')
plt.plot(history.epoch,history.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')
#plt.savefig('C:\\Users\\HP\\Downloads\\Whole Dataset\\tumor_loss_plot.png')